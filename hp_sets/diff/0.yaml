attn_implementation: flash_attention_2
base_hf_repo: facebook/mms-1b-all
dataloader_num_workers: 16
effective_batch_size: 128
fp16: true
job_path: src/mms_blog_post.rocm.job.yaml
learning_rate: 0.0001
num_train_epochs: 3
per_device_eval_batch_size: 256
per_device_eval_batch_total_seconds: 2100.0
per_device_train_batch_size: 128
per_device_train_batch_total_seconds: 2100.0
should_freeze_base_model: false
torch_compile: false
