attn_implementation: flash_attention_2
base_hf_repo: facebook/mms-1b-all
dataloader_num_workers: 16
effective_batch_size: 128
fp16: true
job_path: src/mms_blog_post.a100.job.yaml
job_stem: src/mms_blog_post
job_type: a100
num_train_epochs: 3
per_device_eval_batch_size: 256
per_device_eval_batch_total_seconds: 2100.0
per_device_train_batch_size: 128
per_device_train_batch_total_seconds: 2100.0
should_freeze_base_model: true
torch_compile: false
