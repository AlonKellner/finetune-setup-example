activation_dropout: 0.05
adapter_learning_rate: 0.002
architecture: w2v-bert2
attention_dropout: 0.05
attn_implementation: eager
base_hf_repo: facebook/w2v-bert-2.0
dataloader_num_workers: 20
eval_limit: 10000
final_dropout: 0.05
fp16: true
hidden_dropout: 0.05
job_path: src/mms_blog_post.a100.job.yaml
job_stem: src/mms_blog_post
job_type: a100
layerdrop: 0.05
logging_nan_inf_filter: false
num_train_epochs: 2
per_device_eval_batch_total_seconds: 900.0
per_device_train_batch_total_seconds: 900.0
pretrained_learning_rate: 0.0001
push_to_hub: true
sp_bpe_dropout: 0.0
sp_vocab_size: 48
train_limit: 100000
