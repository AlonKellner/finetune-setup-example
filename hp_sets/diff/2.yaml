attn_implementation: flash_attention_2
base_hf_repo: facebook/mms-1b-all
dataloader_num_workers: 16
effective_batch_size: 4
fp16: true
learning_rate: 5.0e-05
num_train_epochs: 3
per_device_eval_batch_total_seconds: 2100.0
per_device_train_batch_size: 4
per_device_train_batch_total_seconds: 2100.0
should_freeze_base_model: false
torch_compile: false
