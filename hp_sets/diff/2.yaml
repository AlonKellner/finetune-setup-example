activation_dropout: 0.02
adapter_learning_rate: 0.001
architecture: w2v-bert2
attention_dropout: 0.02
attn_implementation: eager
base_hf_repo: facebook/w2v-bert-2.0
dataloader_num_workers: 20
eval_limit: 10000
final_dropout: 0.02
fp16: true
hidden_dropout: 0.02
job_path: src/mms_blog_post.a100.job.yaml
job_stem: src/mms_blog_post
job_type: a100
layerdrop: 0.02
logging_nan_inf_filter: false
num_train_epochs: 3
per_device_eval_batch_total_seconds: 1200.0
per_device_train_batch_total_seconds: 1200.0
pretrained_learning_rate: 1.0e-05
push_to_hub: true
sp_bpe_dropout: 0.0
sp_vocab_size: 48
train_limit: 100000
